<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>消息队列-kafka-1 | Willis's Note</title><link rel="stylesheet" type="text/css" href="/willis-blog/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/willis-blog/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/willis-blog/favicon.ico"><link rel="apple-touch-icon" href="/willis-blog/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/willis-blog/apple-touch-icon.png"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">消息队列-kafka-1</h1><a id="logo" href="/willis-blog/.">Willis's Note</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/willis-blog/."><i class="fa fa-home"> 首页</i></a><a href="/willis-blog/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/willis-blog/about/"><i class="fa fa-user"> 关于</i></a><a href="/willis-blog/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">消息队列-kafka-1</h1><div class="post-meta">2021-08-04<script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="post-content"><h2 id="入门-amp-简介"><a href="#入门-amp-简介" class="headerlink" title="入门&amp;简介"></a>入门&amp;简介</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kafka是一个消息服务器,特点: <font color='#BD1232'>速度快,吞吐量大</font>. 并没有实现标准的消息接口,他自己提供的api即为它的接口.一个kafka服务运行的实例叫做一个<strong>broker</strong>. <strong>kafka集群</strong>具有高扩展性和容错性,一旦及群众任何一个server挂掉,其他server将会接管他的工作以确保集群正确工作且没有数据丢失.<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kafka消息组成一般有key、value、timestamp以及一些可选的元数据信息.消息一般由消息<strong>生产者</strong>发送到<strong>主题「topic」</strong>中,然后消费者可以从topic中拉取消息.<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个topic可以有多个分区「partition」,并且这些分区可以分布在多台服务器上以“topic名称-分区编号”的格式保存在log.dir下,如图,这样kafka客户端就可以同时在多台kafka服务器上进行读写操作.这也是kafka拥有了能处理高并发(十万甚至百万)消息的能力原因之一.一般拥有相同的key的事件/消息「event」会被写到相同的分区中. <font color='#B923D9'>Kafka总是将消息写入Partition对应的文件，消息保存多久取决于服务器的配置，可以按照时间删除（默认3天），也可以按照文件大小删除，因此，只要Consumer在离线期内的消息还没有被删除，再次上线仍然可以接收到完整的消息流。「也就是如果消息永不过期,那么消息将一直保存下来,直到撑爆磁盘」</font><br><img src="/willis-blog/images/2021-08-04/data-persist-1.png" alt="topic持久化存储.logdir配置为/tmp/kafka-logs/server-2,分区数配置为1(编号从0开始),topic名称为willis_topic-a"><br><img src="/willis-blog/images/2021-08-04/streams-and-tables-p1_p4.png" alt="topic分区-引自官网"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;消息的消费一般是靠消费者自己去pull消息, 客户端会存储它接收到的最后一个消息的offsetId，再次上线后按上次的offsetId查询。<strong>offsetId</strong>是Kafka标识某个Partion的每一条消息的递增整数，客户端通常将它存储在ZooKeeper中(旧版本kafka)。新版本的kafka回报存在log_dir目录下的__consumer_offsets_xxx文件夹中.<font color="#406F80" size=4>由于Zookeeper并不适合大批量的频繁写入操作，新版Kafka已推荐将consumer的位移信息保存在Kafka内部的topic中. __consumer_offsets是kafka自行创建的，和普通的topic相同,它存在的目的之一就是保存consumer提交的位移.</font><br><img src="/willis-blog/images/2021-08-04/offset-1.png" alt="topic-offset形式"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因为消息是通过消费者自行pull,而且消费者可以从任意消息开始获取,因此,消息一定会持久化起来的.kafka将消息分成一个个的<strong>segment</strong>,并保存在文件系统中.<font color='#BD1232'>大家的普遍认知, 文件系统速度慢?其实这要看怎么使用. 如果是随机读写,的确很慢. 但kafka采用顺序读写,并且巧妙的组织了索引,记录了数据的地址和偏移量,读写速度很快</font></p>
<figure class="highlight text"><figcaption><span>[官网原文](https://kafka.apache.org/documentation/#persistence)</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">   Kafka relies heavily on the filesystem for storing and caching messages. There is a general </span><br><span class="line">perception that &quot;disks are slow&quot; which makes people skeptical that a persistent structure can </span><br><span class="line">offer competitive performance. In fact disks are both much slower and much faster than people </span><br><span class="line">expect depending on how they are used; and a properly designed disk structure can often be as </span><br><span class="line">fast as the network.</span><br><span class="line">   The key fact about disk performance is that the throughput of hard drives has been diverging。</span><br><span class="line">from the latency of a disk seek for the last decade. As a result the performance of linear writes </span><br><span class="line">on a JBOD configuration with six 7200rpm SATA RAID-5 array is about 600MB/sec but the performance </span><br><span class="line">of random writes is only about 100k/sec—a difference of over 6000X. These linear reads and writes </span><br><span class="line">are the most predictable of all usage patterns, and are heavily optimized by the operating system. </span><br><span class="line">A modern operating system provides read-ahead and write-behind techniques that prefetch data in </span><br><span class="line">large block multiples and group smaller logical writes into large physical writes. A further </span><br><span class="line">discussion of this issue can be found in this ACM Queue article; they actually find that sequential</span><br><span class="line">disk access can in some cases be faster than random memory access!</span><br></pre></td></tr></table></figure>
<h3 id="消费者组「group」"><a href="#消费者组「group」" class="headerlink" title="消费者组「group」"></a>消费者组「group」</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;组在kafka中就是实现单播和广播的重要方式.如果x个消费者都在同一个组group1,且从topic1拉取消息,那么这x个消费者中,只有一个消费者会消费这个消息; 如果存在x个消费者,都在不同的组中,那么这x个消费者都会消费消息.也就是说, 可以把group理解成一个大的消费者[集群].消息的消费是以组为单位进行,然后组在确定由该组下的哪一个consumer进行消费.</p>
<h3 id="持久化-分段存储"><a href="#持久化-分段存储" class="headerlink" title="持久化-分段存储"></a>持久化-分段存储</h3><p><img src="/willis-blog/images/2021-08-04/segment-1.png" alt="segment的存储格式"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在log_dir下, 每个group+partition会生成一个路径,在该路径下保存了segment文件.<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因为消息是通过消费者自行pull索引文件（Index File）和数据文件（Data File）。索引文件存的是消息的索引信息，帮助快速定位到某条消息。数据文件存储的是具体的消息内容。消息生产者根据topic和partition定位到具体路径,将消息顺序写入到相关分段,消费者拉取消息时,根据offset定位到相关segment,并找到具体位置进行消息拉取.</p>
<h4 id="消息结构"><a href="#消息结构" class="headerlink" title="消息结构"></a>消息结构</h4><figure class="highlight text"><figcaption><span>[参考官网](https://kafka.apache.org/documentation/#messages)</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">baseOffset: int64</span><br><span class="line">batchLength: int32</span><br><span class="line">partitionLeaderEpoch: int32</span><br><span class="line">magic: int8 (current magic value is 2)</span><br><span class="line">crc: int32</span><br><span class="line">attributes: int16</span><br><span class="line">    bit 0~2:</span><br><span class="line">        0: no compression</span><br><span class="line">        1: gzip</span><br><span class="line">        2: snappy</span><br><span class="line">        3: lz4</span><br><span class="line">        4: zstd</span><br><span class="line">    bit 3: timestampType</span><br><span class="line">    bit 4: isTransactional (0 means not transactional)</span><br><span class="line">    bit 5: isControlBatch (0 means not a control batch)</span><br><span class="line">    bit 6~15: unused</span><br><span class="line">lastOffsetDelta: int32</span><br><span class="line">firstTimestamp: int64</span><br><span class="line">maxTimestamp: int64</span><br><span class="line">producerId: int64</span><br><span class="line">producerEpoch: int16</span><br><span class="line">baseSequence: int32</span><br><span class="line">records: [Record]</span><br></pre></td></tr></table></figure>
<p><strong>Record结构</strong></p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">length: varint</span><br><span class="line">attributes: int8</span><br><span class="line">    bit 0~7: unused</span><br><span class="line">timestampDelta: varlong</span><br><span class="line">offsetDelta: varint</span><br><span class="line">keyLength: varint</span><br><span class="line">key: byte[]</span><br><span class="line">valueLen: varint</span><br><span class="line">value: byte[]</span><br><span class="line">Headers =&gt; [Header]</span><br></pre></td></tr></table></figure>

<p><strong>Header结构</strong></p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">headerKeyLength: varint</span><br><span class="line">headerKey: String</span><br><span class="line">headerValueLength: varint</span><br><span class="line">Value: byte[]</span><br></pre></td></tr></table></figure>

<h3 id="消息查找"><a href="#消息查找" class="headerlink" title="消息查找"></a>消息查找</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;消息查找的过程, 参考上图「segment的存储格式」.如索引文件368769.index，其表示文件存储的第一条 Kafka 消息的偏移量为 368770。而 368769 表示的是 0000.index 这个索引文件的最后一条消息.在索引文件中,格式大概为[N,Position]. N代表索引文件中第几条记录, Position代表数据在物理存储介质中的偏移地址.例如, 当要找offset为368772的记录时,就在索引文件368769.index中进行查找,因为368769 + 3=368772, 所以文件368769.index中的第三条记录就是目标数据.如下图,数据就是在368769.log中,物理偏移地址为349的位置.<br><img src="/willis-blog/images/2021-08-04/index-1.png" alt="索引文件内容结构"></p>
<h4 id="稀疏索引"><a href="#稀疏索引" class="headerlink" title="稀疏索引"></a>稀疏索引</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kafka在索引文件中并不会保存所有消息的偏移地址.<font color=#BD1232>这是因为,Kafka 的消息太多了，如果把所有消息的「offset，物理偏移量」信息都存入 index 文件的话，那么这个文件太大了，无法一次性存入内存。而如果无法一次性存入内容，就会导致需要多次去读取，但每次去读磁盘又会降低读取效率。</font><br>于是,诞生了稀疏索引的创意,例如,我本来要存储 1 万个消息，但现在我只存 5 千个. 就像上图的 Kafka 索引文件一样跳着存储。如果我要寻找第 7 条消息，那我只需要找到第 6 条消息的物理偏移量。之后在读取数据文件的时候直接跳过 1 条消息就可以了(是不是很像跳表?)。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;稀疏索引要关注亮点:密度与均匀程度. 例如, 例如原本有 1 万个消息 offset 索引，你现在减到了 100 个，那就太少了, 会增加查找的时间成本;再比如,还是 1 万个消息的 offset 索引为例，如果你弄了 8000 个索引。这时候索引密度应该是没问题的。但是这 8000 个索引全都是第 1 - 8000 条消息的索引，最后一个索引是 8000 - 1 万的。那么当要读取的 offset 坐落于这个区间时，读取速度也会很慢. Kafka要实现稀疏索引,需要找到一个平衡点,既保证可以接受的查找速度,又可以减少存储空间.</p>
<h3 id="一些重要的配置"><a href="#一些重要的配置" class="headerlink" title="一些重要的配置"></a>一些重要的配置</h3><h4 id="broker配置"><a href="#broker配置" class="headerlink" title="broker配置"></a>broker配置</h4><figure class="highlight shell"><figcaption><span>[broker配置:</span><a target="_blank" rel="noopener" href="https://kafka.apache.org/documentation/#brokerconfigs]">link</a></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> broker的端口,近似于过期配置, 因为这个配置只有在没有配置listener配置的时候才会生效.</span></span><br><span class="line">port</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="producer"><a href="#producer" class="headerlink" title="producer"></a>producer</h4><figure class="highlight shell"><figcaption><span>[生产者配置说明,全部配置参考:https://kafka.apache.org/documentation/#producerconfigs]</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 批量发送的大小,单位是字节(byte).默认16384</span></span><br><span class="line">batch.size. </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">批量发送的等待时间.消息不会直接投递,会先填充到缓冲区,如果等了linger.ms毫秒, 缓冲区还没填满到batch.size.就直接投递出去了.如果没到linger.ms毫秒,缓冲区就满了,消息也会直接投递出去. 如果设置为0,有消息就直接投递出去了</span></span><br><span class="line">linger.ms. </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 是否启动幂等支持.默认<span class="literal">false</span>,即不支持幂等.启用后,消息将整好被投递一次[exactly once].</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 不启用的情况下,如果客户端认为发送失败,会重试,有可能造成消息重复投递,即保证消息至少投递一次[at list once]</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 幂等支持, asks必须设置为all才能生效. 一般启用了这个配置后, acks会自动变成all</span></span><br><span class="line">enable.idempotence. </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 消息确认.[0,1,-1,all].</span> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 当设置为0,消息生产者只管发,不管成不成功,不用等待服务器响应.一旦服务器没有收到消息,生产者也不知道,所以有可能消息丢失.</span> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果设置为1,leader 节点会回复消息确认; 这种情况下,如果主节点回复确认后,在从节点复制数据完成之前,主节点挂掉,消息就丢失了</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果设置成all或-1,要等所有相关节点和副本节点都成功才会确认.</span></span><br><span class="line">acks. </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 消息投递的重试次数.</span></span><br><span class="line">retries.</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 消息投递超时时间.默认120000(2分钟).这个时间限制了批量等待时间+发送超时时间(包含重试)的总时间.所以他的设置应该大于等于[request.timeout.ms] + [linger.ms]的和</span></span><br><span class="line">delivery.timeout.ms. </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 消息发送超时时间. 如果一个发送请求,在这么多时间没收到返回, 那么就会在retries机会耗尽前进行重试投递</span></span><br><span class="line">request.timeout.ms. </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="consumer"><a href="#consumer" class="headerlink" title="consumer"></a>consumer</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<blockquote>
<p>关于幂等实现原理参考官网解释:<a target="_blank" rel="noopener" href="https://kafka.apache.org/documentation/#semantics">https://kafka.apache.org/documentation/#semantics</a></p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Since 0.11.0.0, the Kafka producer also supports an idempotent delivery option which guarantees that resending will not result in duplicate entries in the log. To achieve this, the broker assigns each producer an ID and deduplicates messages using a sequence number that is sent by the producer along with every message.</span><br></pre></td></tr></table></figure>

<p>从0.11.0.0版本开始，kafka支持了消息的幂等投递，实现原理：broker给每个生产者分配了一个ID，并且每个消息在投递时会附带一个消息序号，用这个消息序号来解决重复（deduplicates）问题。</p>
<h3 id="kafka集群"><a href="#kafka集群" class="headerlink" title="kafka集群"></a>kafka集群</h3><p>topic的一个分区的副本总数(一个主分区+多个副本分区)不能大于broker节点数量,否则报错.<br>每个topic可以指定任意数目分区,且会均匀分布在构成集群的broker中. 每个分区可以指定任意副本,单副本总数必须小于broker数量</p>
<h4 id="简单搭建一个集群的步骤"><a href="#简单搭建一个集群的步骤" class="headerlink" title="简单搭建一个集群的步骤"></a>简单搭建一个集群的步骤</h4><p>borker的server.properties配置以下几项</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># broker的ID.注意保证集群中每个broker的id唯一. 我三个节点,id分别是0,1,2</span></span><br><span class="line"><span class="meta">broker.id</span>=<span class="string">0</span></span><br><span class="line"><span class="comment"># 逗号分隔的url列表. 格式是listener-name://host:port. 用来定义Kafka Broker的Listener的配置项。</span></span><br><span class="line"><span class="comment"># 一般listener-name是安全协议的名称, 如果不是,需要在listener.security.protocol.map配置中指定.</span></span><br><span class="line"><span class="comment"># listener.security.protocol.map这个配置是一个map, key是listener-name,value就是安全协议(如PLAINTEXT、SSL等等)</span></span><br><span class="line"><span class="attr">listeners</span> = <span class="string">PLAINTEXT://localhost:9092</span></span><br><span class="line"><span class="comment"># 专门用于Kafka集群中Broker之间的通信. 我在本机搭的集群,没配置这个项</span></span><br><span class="line"><span class="meta">inter.broker.listener.name</span> = <span class="string">PLAINTEXT</span></span><br><span class="line"><span class="comment"># 该项是发布到zookeeper中为客户端(生产者或消费者)使用,其实就是让zk记录下自己的通信地址信息.如果没有配置该项,就会使用listener配置.</span></span><br><span class="line"><span class="comment"># 该项在使用容器部署kafka时十分有效. 客户端使用一般使用宿主机ip,kafka在容器内一般是一个虚拟ip, 使用宿主机host进行访问kafka,会根据端口映射到容器内部.</span></span><br><span class="line"><span class="meta">advertised.listeners</span>=<span class="string">PLAINTEXT://localhost:9092</span></span><br><span class="line"><span class="comment"># 因为我实在本机搭建的的集群, 采用不同的端口区分broker,log.dirs要配置不同的路径</span></span><br><span class="line"><span class="meta">log.dirs</span>=<span class="string">/tmp/kafka-logs/server-2</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 分别指定配置文件,启动3个broker</span><br><span class="line">.&#x2F;bin&#x2F;kafka-server-start.sh .&#x2F;config&#x2F;server-2.properties&amp;</span><br></pre></td></tr></table></figure>

<p>连接上zk,看进群是否启动成功.<br><img src="/willis-blog/images/2021-08-04/jq-1.png" alt="连上zk"><br>通过查看zk节点, 得知集群大家成功,此时的controller是broker.id=0的节点<br><font color>关于listener配置,参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_38251332/article/details/105638535">https://blog.csdn.net/weixin_38251332/article/details/105638535</a></font></p>
<h3 id="Console命令"><a href="#Console命令" class="headerlink" title="Console命令"></a>Console命令</h3><figure class="highlight shell"><figcaption><span>[命令行快捷操作]</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kafka修改topic配置</span></span><br><span class="line">bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name my-topic --alter --add-config max.message.bytes=128000 --add-config flush.messages=2 </span><br><span class="line"><span class="meta">#</span><span class="bash"> 消费者console</span></span><br><span class="line">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --group willis-group-1 --topic willis-topic-1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 打印topic信息</span></span><br><span class="line">bin/kafka-topics.sh --describe --topic willis-topic-1 --bootstrap-server localhost:9092</span><br><span class="line"><span class="meta">#</span><span class="bash"> 生产者console</span></span><br><span class="line">bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic willis-topic-1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看消费者组信息</span></span><br><span class="line">bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group willis-group-1</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="java项目集成"><a href="#java项目集成" class="headerlink" title="java项目集成"></a>java项目集成</h3><h4 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ws.mq.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.admin.NewTopic;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Value;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.core.DefaultKafkaProducerFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.core.KafkaTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.core.ProducerFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.transaction.KafkaTransactionManager;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> willis</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 2021年08月12日 11:16</span></span><br><span class="line"><span class="comment"> * 说明</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerConfig</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;spring.kafka.bootstrap-servers:&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String bootServers;</span><br><span class="line">    <span class="comment">/************************Producer配置信息begin***********************/</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProducerFactory&lt;String, String&gt; <span class="title">producerFactory</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        DefaultKafkaProducerFactory kafkaProducerFactory = <span class="keyword">new</span> DefaultKafkaProducerFactory(producerConfigs());</span><br><span class="line">        <span class="comment">// 支持事务</span></span><br><span class="line">        kafkaProducerFactory.transactionCapable();</span><br><span class="line">        kafkaProducerFactory.setTransactionIdPrefix(<span class="string">&quot;test-trans-&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> kafkaProducerFactory;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String, Object&gt; <span class="title">producerConfigs</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Map&lt;String, Object&gt; props = <span class="keyword">new</span> HashMap();</span><br><span class="line">        props.put(org.apache.kafka.clients.producer.ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootServers);</span><br><span class="line">        props.put(org.apache.kafka.clients.producer.ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</span><br><span class="line">        props.put(org.apache.kafka.clients.producer.ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</span><br><span class="line">        <span class="comment">// linger.ms, 默认0，代表来了消息就会发送。 单位毫秒。设置称一个比较大的值，会将消息暂存到缓冲区，当缓冲区使用量达到batch.size或者等待时间达到了linger.ms，就会将缓冲区中的消息发送出去</span></span><br><span class="line">        props.put(org.apache.kafka.clients.producer.ProducerConfig.LINGER_MS_CONFIG, <span class="number">3000</span>);</span><br><span class="line">        props.put(org.apache.kafka.clients.producer.ProducerConfig.ACKS_CONFIG, <span class="string">&quot;all&quot;</span>);</span><br><span class="line">        props.put(org.apache.kafka.clients.producer.ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// See https://kafka.apache.org/documentation/#producerconfigs for more properties</span></span><br><span class="line">        <span class="keyword">return</span> props;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> KafkaTemplate&lt;String, String&gt; <span class="title">kafkaTemplate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> KafkaTemplate&lt;String, String&gt;(producerFactory());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> KafkaTransactionManager <span class="title">transactionManager</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        KafkaTransactionManager manager = <span class="keyword">new</span> KafkaTransactionManager(producerFactory());</span><br><span class="line">        <span class="keyword">return</span> manager;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 提前建立好topic配置</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> NewTopic <span class="title">willisTopic</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        NewTopic newTopic = <span class="keyword">new</span> NewTopic(<span class="string">&quot;willis_topic-a&quot;</span>, <span class="number">4</span>, (<span class="keyword">short</span>) <span class="number">3</span>);</span><br><span class="line">        <span class="keyword">return</span> newTopic;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> NewTopic <span class="title">willis2Topic</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        NewTopic newTopic = <span class="keyword">new</span> NewTopic(<span class="string">&quot;willis-2&quot;</span>, <span class="number">1</span>, (<span class="keyword">short</span>) <span class="number">3</span>);</span><br><span class="line">        <span class="keyword">return</span> newTopic;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> NewTopic <span class="title">willis3Topic</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        NewTopic newTopic = <span class="keyword">new</span> NewTopic(<span class="string">&quot;willis-3&quot;</span>, <span class="number">4</span>, (<span class="keyword">short</span>) <span class="number">3</span>);</span><br><span class="line">        <span class="keyword">return</span> newTopic;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/************************Producer配置信息begin***********************/</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ws.mq.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.core.KafkaTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.support.SendResult;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.concurrent.ListenableFuture;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> willis</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 2021年08月10日 15:43</span></span><br><span class="line"><span class="comment"> * 说明</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaProducer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(KafkaProducer.class);</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> KafkaTemplate&lt;String, String&gt; kafkaTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendMsg</span><span class="params">(String topic, String msg)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        ProducerRecord&lt;String, String&gt; pr = <span class="keyword">new</span> ProducerRecord(topic, msg);</span><br><span class="line">        pr.headers().add(<span class="string">&quot;type&quot;</span>, msg.getClass().getName().getBytes(<span class="string">&quot;utf-8&quot;</span>));</span><br><span class="line">        ListenableFuture&lt;SendResult&lt;String, String&gt;&gt; sendResultListenableFuture = kafkaTemplate.send(pr);</span><br><span class="line">        logger.info(<span class="string">&quot;消息已投递，成不成功不知道&quot;</span>);</span><br><span class="line">        sendResultListenableFuture.addCallback(arg -&gt; &#123;</span><br><span class="line">            logger.info(<span class="string">&quot;消息投递成功:&#123;&#125;&quot;</span>, arg.getProducerRecord());</span><br><span class="line">        &#125;, arg-&gt;&#123;</span><br><span class="line">            logger.error(<span class="string">&quot;消息投递失败:&#123;&#125;&quot;</span>, arg.getMessage(), arg.getCause());</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendWithTrans</span><span class="params">(String topic, List&lt;String&gt; msg)</span> </span>&#123;</span><br><span class="line">        kafkaTemplate.executeInTransaction(operations -&gt; &#123;</span><br><span class="line">            <span class="comment">// 同时发n条记录</span></span><br><span class="line">            <span class="keyword">for</span> (String s : msg) &#123;</span><br><span class="line">                <span class="comment">// 一旦中间执行异常，事务回滚</span></span><br><span class="line">                ProducerRecord&lt;String, String&gt; pr = <span class="keyword">new</span> ProducerRecord(topic, s);</span><br><span class="line">                operations.send(pr);</span><br><span class="line">                <span class="keyword">if</span> (s.contains(<span class="string">&quot;fuck&quot;</span>)) &#123;</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">&quot;Oh, no fuck，消息都不会发出去哦&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h4><figure class="highlight java"><figcaption><span>[配置代码]</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerConfigs</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;spring.kafka.bootstrap-servers:&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String bootServers;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> Map&lt;String, Object&gt; <span class="title">consumerConfigs</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Map&lt;String, Object&gt; prop = <span class="keyword">new</span> HashMap&lt;String, Object&gt;();</span><br><span class="line">        prop.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootServers );</span><br><span class="line">        prop.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</span><br><span class="line">        prop.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</span><br><span class="line">        prop.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="keyword">false</span>);</span><br><span class="line">        <span class="keyword">return</span> prop;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ConsumerFactory&lt;String, String&gt; <span class="title">consumerFactory</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ConsumerFactory consumerFactory = <span class="keyword">new</span> DefaultKafkaConsumerFactory(consumerConfigs());</span><br><span class="line">        <span class="keyword">return</span> consumerFactory;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Bean(name = &quot;containerFactory&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> KafkaListenerContainerFactory <span class="title">containerFactory</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ConcurrentKafkaListenerContainerFactory factory = <span class="keyword">new</span> ConcurrentKafkaListenerContainerFactory();</span><br><span class="line">        factory.setConsumerFactory(consumerFactory());</span><br><span class="line">        <span class="comment">// 是否批量消费，默认false,当为true时，一次获取多条消息</span></span><br><span class="line">        factory.setBatchListener(<span class="keyword">true</span>);</span><br><span class="line">        <span class="comment">// 只有在这里配置才能使用手动提交，上面consumerConfigs中配置的自动提交false没啥用</span></span><br><span class="line">        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL);</span><br><span class="line">        <span class="keyword">return</span> factory;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaConsumer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(KafkaConsumer.class);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 批量接收消息, 用List即可</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="meta">@KafkaListener(topics = &quot;willis_topic-a&quot;, groupId = &quot;group_a&quot;, containerFactory = &quot;containerFactory&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onRegistrationMessage</span><span class="params">(<span class="meta">@Payload</span> List&lt;String&gt; message, Acknowledgment acknowledgment)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        logger.info(<span class="string">&quot;received registration message: &#123;&#125;&quot;</span>, message);</span><br><span class="line">        <span class="comment">// 设置为手动提交后，一定要记得ack，不然会一致重复消费</span></span><br><span class="line">        acknowledgment.acknowledge();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight yml"><figcaption><span>[springboot配置]</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">kafka:</span></span><br><span class="line">    <span class="comment"># 集群配置</span></span><br><span class="line">    <span class="attr">bootstrap-servers:</span> <span class="string">&quot;localhost:9092,localhost:9093,localhost:9094&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">8081</span></span><br></pre></td></tr></table></figure>

<p>更多配置参考:<a target="_blank" rel="noopener" href="https://kafka.apache.org/documentation/#consumerconfigs">https://kafka.apache.org/documentation/#consumerconfigs</a></p>
<hr>
<p>参考文献<br><font color=#406F80 size=3><a target="_blank" rel="noopener" href="https://kafka.apache.org/intro">https://kafka.apache.org/intro</a></font><br><font color=#406F80 size=3><a target="_blank" rel="noopener" href="https://blog.csdn.net/u010634066/article/details/109306637">https://blog.csdn.net/u010634066/article/details/109306637</a></font><br><font color=#406F80 size=3><a target="_blank" rel="noopener" href="https://shuyi.tech/archives/kafka-message-storage">https://shuyi.tech/archives/kafka-message-storage</a></font><br><font color=#406F80 size=3><a target="_blank" rel="noopener" href="https://juejin.cn/post/6893410969611927566">https://juejin.cn/post/6893410969611927566</a></font></p>
</div><div class="tags"><a href="/willis-blog/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"><i class="fa fa-tag"></i>消息队列</a><a href="/willis-blog/tags/kafka/"><i class="fa fa-tag"></i>kafka</a></div><div class="post-nav"><a class="pre" href="/willis-blog/2021/09/25/Nginx-%E9%85%8D%E7%BD%AE/">Nginx-配置</a><a class="next" href="/willis-blog/2021/06/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/">操作系统-内存管理</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="https://songkv5.github.io/blog"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/willis-blog/tags/Mysql/" style="font-size: 15px;">Mysql</a> <a href="/willis-blog/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/willis-blog/tags/elastic/" style="font-size: 15px;">elastic</a> <a href="/willis-blog/tags/Dubbo/" style="font-size: 15px;">Dubbo</a> <a href="/willis-blog/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/" style="font-size: 15px;">微服务</a> <a href="/willis-blog/tags/%E6%B8%B8%E7%8E%A9/" style="font-size: 15px;">游玩</a> <a href="/willis-blog/tags/Swarm/" style="font-size: 15px;">Swarm</a> <a href="/willis-blog/tags/Nginx/" style="font-size: 15px;">Nginx</a> <a href="/willis-blog/tags/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/" style="font-size: 15px;">反向代理</a> <a href="/willis-blog/tags/IO/" style="font-size: 15px;">IO</a> <a href="/willis-blog/tags/%E5%90%8C%E6%AD%A5IO/" style="font-size: 15px;">同步IO</a> <a href="/willis-blog/tags/%E5%BC%82%E6%AD%A5IO/" style="font-size: 15px;">异步IO</a> <a href="/willis-blog/tags/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/" style="font-size: 15px;">多路复用</a> <a href="/willis-blog/tags/JVM/" style="font-size: 15px;">JVM</a> <a href="/willis-blog/tags/Java/" style="font-size: 15px;">Java</a> <a href="/willis-blog/tags/%E5%90%8C%E6%AD%A5/" style="font-size: 15px;">同步</a> <a href="/willis-blog/tags/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/" style="font-size: 15px;">线程安全</a> <a href="/willis-blog/tags/%E6%8C%87%E9%92%88%E5%8E%8B%E7%BC%A9/" style="font-size: 15px;">指针压缩</a> <a href="/willis-blog/tags/jvm/" style="font-size: 15px;">jvm</a> <a href="/willis-blog/tags/java/" style="font-size: 15px;">java</a> <a href="/willis-blog/tags/InnoDb/" style="font-size: 15px;">InnoDb</a> <a href="/willis-blog/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 15px;">操作系统</a> <a href="/willis-blog/tags/%E7%94%A8%E6%88%B7%E6%80%81/" style="font-size: 15px;">用户态</a> <a href="/willis-blog/tags/%E6%A0%B8%E6%80%81/" style="font-size: 15px;">核态</a> <a href="/willis-blog/tags/%E7%AE%A1%E6%80%81/" style="font-size: 15px;">管态</a> <a href="/willis-blog/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" style="font-size: 15px;">消息队列</a> <a href="/willis-blog/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/willis-blog/tags/Redis/" style="font-size: 15px;">Redis</a> <a href="/willis-blog/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 15px;">数据结构</a> <a href="/willis-blog/tags/%E5%8E%8B%E7%BC%A9%E8%A1%A8/" style="font-size: 15px;">压缩表</a> <a href="/willis-blog/tags/%E5%BF%AB%E8%A1%A8/" style="font-size: 15px;">快表</a> <a href="/willis-blog/tags/%E8%B7%B3%E8%A1%A8/" style="font-size: 15px;">跳表</a> <a href="/willis-blog/tags/%E8%BF%9B%E7%A8%8B/" style="font-size: 15px;">进程</a> <a href="/willis-blog/tags/%E7%BA%BF%E7%A8%8B/" style="font-size: 15px;">线程</a> <a href="/willis-blog/tags/%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98/" style="font-size: 15px;">共享内存</a> <a href="/willis-blog/tags/%E5%86%85%E5%AD%98/" style="font-size: 15px;">内存</a> <a href="/willis-blog/tags/netty/" style="font-size: 15px;">netty</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/willis-blog/2021/10/23/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/">Redis数据结构</a></li><li class="post-list-item"><a class="post-list-link" href="/willis-blog/2021/10/22/JVM%E5%90%8C%E6%AD%A5%E6%94%AF%E6%92%91/">JVM的同步支撑</a></li><li class="post-list-item"><a class="post-list-link" href="/willis-blog/2021/10/22/%E5%85%B3%E4%BA%8EJVM%E6%8C%87%E9%92%88%E5%8E%8B%E7%BC%A9/">关于JVM指针压缩</a></li><li class="post-list-item"><a class="post-list-link" href="/willis-blog/2021/10/14/Netty%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E4%B8%8E%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/">Netty实现原理与源码分析</a></li><li class="post-list-item"><a class="post-list-link" href="/willis-blog/2021/10/10/IO%E7%9A%84%E8%BF%9B%E5%8C%96/">IO的进化过程</a></li><li class="post-list-item"><a class="post-list-link" href="/willis-blog/2021/09/25/Nginx-%E9%85%8D%E7%BD%AE/">Nginx-配置</a></li><li class="post-list-item"><a class="post-list-link" href="/willis-blog/2021/08/04/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-kafka-1/">消息队列-kafka-1</a></li><li class="post-list-item"><a class="post-list-link" href="/willis-blog/2021/06/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/">操作系统-内存管理</a></li><li class="post-list-item"><a class="post-list-link" href="/willis-blog/2021/06/03/Maven%E7%9A%84docker%E6%8F%92%E4%BB%B6/">Maven的Docker插件</a></li><li class="post-list-item"><a class="post-list-link" href="/willis-blog/2021/05/23/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B&%E7%BA%BF%E7%A8%8B/">操作系统-进程/线程</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.baidu.com/" title="百度" target="_blank">百度</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2024 <a href="/willis-blog/." rel="nofollow">Willis's Note.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/willis-blog/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/willis-blog/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/willis-blog/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/willis-blog/js/smartresize.js?v=1.0.0"></script></div></body></html>